// tools/benchmark/utils.go
package benchmark

import (
	"fmt"
	"math"
	"os"
	"path/filepath"
	"runtime"
	"time"
)

// RunGarbageCollection è¿è¡Œåƒåœ¾å›æ”¶å¹¶æµ‹é‡è€—æ—¶
func RunGarbageCollection() (duration time.Duration) {
	start := time.Now()
	runtime.GC()
	return time.Since(start)
}

// GetMemoryStats è·å–å½“å‰å†…å­˜ç»Ÿè®¡
func GetMemoryStats() map[string]float64 {
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)

	return map[string]float64{
		"alloc_mb":       float64(memStats.Alloc) / 1024 / 1024,
		"total_alloc_mb": float64(memStats.TotalAlloc) / 1024 / 1024,
		"sys_mb":         float64(memStats.Sys) / 1024 / 1024,
		"heap_alloc_mb":  float64(memStats.HeapAlloc) / 1024 / 1024,
		"heap_sys_mb":    float64(memStats.HeapSys) / 1024 / 1024,
		"num_gc":         float64(memStats.NumGC),
		"gc_pause_ms":    float64(memStats.PauseTotalNs) / 1_000_000,
	}
}

// PrintMemoryStats æ‰“å°å†…å­˜ç»Ÿè®¡ä¿¡æ¯
func PrintMemoryStats(label string) {
	stats := GetMemoryStats()

	fmt.Printf("\nğŸ“Š %s å†…å­˜ç»Ÿè®¡:\n", label)
	fmt.Printf("  å½“å‰åˆ†é…: %.2f MB\n", stats["alloc_mb"])
	fmt.Printf("  ç´¯è®¡åˆ†é…: %.2f MB\n", stats["total_alloc_mb"])
	fmt.Printf("  ç³»ç»Ÿå†…å­˜: %.2f MB\n", stats["sys_mb"])
	fmt.Printf("  å †åˆ†é…:   %.2f MB\n", stats["heap_alloc_mb"])
	fmt.Printf("  å †ç³»ç»Ÿ:   %.2f MB\n", stats["heap_sys_mb"])
	fmt.Printf("  GCæ¬¡æ•°:   %.0f\n", stats["num_gc"])
	fmt.Printf("  GCæš‚åœ:   %.2f ms\n", stats["gc_pause_ms"])
}

// MeasureExecutionTime æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´
func MeasureExecutionTime(fn func()) time.Duration {
	start := time.Now()
	fn()
	return time.Since(start)
}

// BenchmarkComponent åŸºå‡†æµ‹è¯•ç»„ä»¶æ€§èƒ½çš„é€šç”¨å‡½æ•°
func BenchmarkComponent(name, componentType string, setupFunc, testFunc, cleanupFunc func()) (*PerformanceMetric, error) {
	fmt.Printf("ğŸ”§ å¼€å§‹æµ‹è¯•ç»„ä»¶: %s (%s)\n", name, componentType)

	// è¿è¡ŒGCç¡®ä¿æµ‹è¯•ç¯å¢ƒå¹²å‡€
	runtime.GC()
	time.Sleep(100 * time.Millisecond)

	// è®°å½•åˆå§‹å†…å­˜
	initialStats := GetMemoryStats()

	// æ‰§è¡Œè®¾ç½®å‡½æ•°
	if setupFunc != nil {
		fmt.Println("  è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
		setupFunc()
	}

	// ç­‰å¾…ç¨³å®š
	time.Sleep(200 * time.Millisecond)

	// è®°å½•æµ‹è¯•å‰å†…å­˜
	preTestStats := GetMemoryStats()

	// æ‰§è¡Œæµ‹è¯•å‡½æ•°å¹¶æµ‹é‡æ—¶é—´
	fmt.Println("  æ‰§è¡Œæµ‹è¯•...")
	executionTime := MeasureExecutionTime(testFunc)

	// è®°å½•æµ‹è¯•åå†…å­˜
	postTestStats := GetMemoryStats()

	// æ‰§è¡Œæ¸…ç†å‡½æ•°
	if cleanupFunc != nil {
		fmt.Println("  æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
		cleanupFunc()
	}

	// å†æ¬¡è¿è¡ŒGCæŸ¥çœ‹æœ€ç»ˆå†…å­˜
	runtime.GC()
	time.Sleep(100 * time.Millisecond)
	finalStats := GetMemoryStats()

	// åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
	metric := NewPerformanceMetric(name, componentType, "benchmark")
	metric.RenderTimeMS = executionTime.Seconds() * 1000

	// è®¡ç®—å†…å­˜å¢é‡
	metric.MemoryUsageMB = postTestStats["alloc_mb"] - preTestStats["alloc_mb"]
	metric.MemoryAllocMB = finalStats["alloc_mb"] - initialStats["alloc_mb"]

	// è·å–å…¶ä»–ç³»ç»Ÿä¿¡æ¯
	metric.Goroutines = runtime.NumGoroutine()
	metric.NumCores = runtime.NumCPU()

	fmt.Printf("âœ… æµ‹è¯•å®Œæˆ - æ‰§è¡Œæ—¶é—´: %.2fms, å†…å­˜å¢é‡: %.2fMB\n",
		metric.RenderTimeMS, metric.MemoryUsageMB)

	return metric, nil
}

// CreateTestReport åˆ›å»ºæµ‹è¯•æŠ¥å‘Š
func CreateTestReport(metrics []*PerformanceMetric, outputPath string) error {
	if len(metrics) == 0 {
		return fmt.Errorf("no metrics to report")
	}

	exporter := NewCSVExporter(filepath.Dir(outputPath))
	exporter.SetFilename(filepath.Base(outputPath))

	return exporter.ExportMetrics(metrics, nil)
}

// ç»„ä»¶å¯¹æ¯”ç»“æœ
type ComponentComparison struct {
	CustomMetrics []*PerformanceMetric
	NativeMetrics []*PerformanceMetric
	CustomSummary map[string]interface{}
	NativeSummary map[string]interface{}
	Comparison    map[string]interface{}
	Conclusion    string
}

// CompareComponents å¯¹æ¯”ä¸¤ä¸ªç»„ä»¶æ€§èƒ½ï¼ˆç§‘å­¦æ–¹æ³•ï¼‰
func CompareComponents(customMetrics, nativeMetrics []*PerformanceMetric) *ComponentComparison {
	if len(customMetrics) == 0 || len(nativeMetrics) == 0 {
		return nil
	}

	// 1. åˆ†åˆ«è®¡ç®—ç»Ÿè®¡æ‘˜è¦
	customSummary := calculateComponentSummary(customMetrics, "custom")
	nativeSummary := calculateComponentSummary(nativeMetrics, "native")

	// 2. ç§‘å­¦å¯¹æ¯”åˆ†æ
	comparison := scientificComparison(customSummary, nativeSummary)

	// 3. ç”Ÿæˆç»“è®º
	conclusion := generateConclusion(comparison)

	return &ComponentComparison{
		CustomMetrics: customMetrics,
		NativeMetrics: nativeMetrics,
		CustomSummary: customSummary,
		NativeSummary: nativeSummary,
		Comparison:    comparison,
		Conclusion:    conclusion,
	}
}

// calculateComponentSummary è®¡ç®—ç»„ä»¶æ€§èƒ½ç»Ÿè®¡æ‘˜è¦
func calculateComponentSummary(metrics []*PerformanceMetric, componentType string) map[string]interface{} {
	if len(metrics) == 0 {
		return nil
	}

	// æå–å…³é”®æŒ‡æ ‡
	var fpsValues, memoryValues, cpuValues []float64
	var totalRenderTime float64

	for _, metric := range metrics {
		fpsValues = append(fpsValues, metric.FPS)
		memoryValues = append(memoryValues, metric.MemoryUsageMB)
		cpuValues = append(cpuValues, metric.CPUPercent)
		totalRenderTime += metric.RenderTimeMS
	}

	// è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
	fpsStats := calculateStatistics(fpsValues)
	memoryStats := calculateStatistics(memoryValues)
	cpuStats := calculateStatistics(cpuValues)

	avgRenderTime := totalRenderTime / float64(len(metrics))

	return map[string]interface{}{
		"component_type": componentType,
		"sample_count":   len(metrics),

		"fps_avg": fpsStats["avg"],
		"fps_min": fpsStats["min"],
		"fps_max": fpsStats["max"],
		"fps_std": fpsStats["std"],
		"fps_cv":  fpsStats["cv"], // å˜å¼‚ç³»æ•°

		"memory_avg": memoryStats["avg"],
		"memory_min": memoryStats["min"],
		"memory_max": memoryStats["max"],
		"memory_std": memoryStats["std"],
		"memory_cv":  memoryStats["cv"],

		"cpu_avg": cpuStats["avg"],
		"cpu_min": cpuStats["min"],
		"cpu_max": cpuStats["max"],
		"cpu_std": cpuStats["std"],
		"cpu_cv":  cpuStats["cv"],

		"render_time_avg": avgRenderTime,
	}
}

// calculateStatistics è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
func calculateStatistics(values []float64) map[string]float64 {
	if len(values) == 0 {
		return nil
	}

	// è®¡ç®—åŸºæœ¬ç»Ÿè®¡
	var sum, min, max float64
	min = math.MaxFloat64

	for _, v := range values {
		sum += v
		if v < min {
			min = v
		}
		if v > max {
			max = v
		}
	}

	avg := sum / float64(len(values))

	// è®¡ç®—æ ‡å‡†å·®
	var variance float64
	for _, v := range values {
		diff := v - avg
		variance += diff * diff
	}
	variance /= float64(len(values))
	std := math.Sqrt(variance)

	// è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆæ ‡å‡†å·®/å‡å€¼ï¼‰
	cv := 0.0
	if avg != 0 {
		cv = (std / avg) * 100
	}

	return map[string]float64{
		"avg": math.Round(avg*100) / 100,
		"min": math.Round(min*100) / 100,
		"max": math.Round(max*100) / 100,
		"std": math.Round(std*100) / 100,
		"cv":  math.Round(cv*100) / 100,
	}
}

// scientificComparison ç§‘å­¦å¯¹æ¯”ä¸¤ä¸ªç»„ä»¶çš„æ€§èƒ½
func scientificComparison(customSummary, nativeSummary map[string]interface{}) map[string]interface{} {
	if customSummary == nil || nativeSummary == nil {
		return nil
	}

	// æå–å…³é”®æŒ‡æ ‡
	customFPSAvg := customSummary["fps_avg"].(float64)
	customMemoryAvg := customSummary["memory_avg"].(float64)
	customCPUAvg := customSummary["cpu_avg"].(float64)

	nativeFPSAvg := nativeSummary["fps_avg"].(float64)
	nativeMemoryAvg := nativeSummary["memory_avg"].(float64)
	nativeCPUAvg := nativeSummary["cpu_avg"].(float64)

	// è®¡ç®—ç›¸å¯¹æ€§èƒ½
	fpsRatio := customFPSAvg / nativeFPSAvg
	memoryRatio := customMemoryAvg / nativeMemoryAvg
	cpuRatio := customCPUAvg / nativeCPUAvg

	// è®¡ç®—æ€§èƒ½å·®å¼‚ç™¾åˆ†æ¯”
	fpsDiffPercent := (customFPSAvg - nativeFPSAvg) / nativeFPSAvg * 100
	memoryDiffPercent := (customMemoryAvg - nativeMemoryAvg) / nativeMemoryAvg * 100
	cpuDiffPercent := (customCPUAvg - nativeCPUAvg) / nativeCPUAvg * 100

	// è®¡ç®—ç»¼åˆæ€§èƒ½è¯„åˆ†
	performanceScore := calculatePerformanceScore(
		fpsRatio, memoryRatio, cpuRatio,
		customSummary["fps_cv"].(float64),
		customSummary["memory_cv"].(float64),
		customSummary["cpu_cv"].(float64),
	)

	// æ˜¾è‘—æ€§åˆ†æ
	significance := analyzeSignificance(
		customSummary, nativeSummary,
		fpsDiffPercent, memoryDiffPercent, cpuDiffPercent,
	)

	return map[string]interface{}{
		// æ€§èƒ½æ¯”ç‡
		"fps_ratio":    math.Round(fpsRatio*1000) / 1000,
		"memory_ratio": math.Round(memoryRatio*1000) / 1000,
		"cpu_ratio":    math.Round(cpuRatio*1000) / 1000,

		// æ€§èƒ½å·®å¼‚ç™¾åˆ†æ¯”
		"fps_diff_percent":    math.Round(fpsDiffPercent*100) / 100,
		"memory_diff_percent": math.Round(memoryDiffPercent*100) / 100,
		"cpu_diff_percent":    math.Round(cpuDiffPercent*100) / 100,

		// æ€§èƒ½è¯„åˆ†
		"performance_score": performanceScore,

		// æ˜¾è‘—æ€§åˆ†æ
		"significance": significance,

		// æ€§èƒ½åˆ†ç±»
		"performance_category": classifyPerformance(
			fpsRatio, memoryRatio, cpuRatio,
			fpsDiffPercent, memoryDiffPercent, cpuDiffPercent,
		),
	}
}

// calculatePerformanceScore è®¡ç®—ç»¼åˆæ€§èƒ½è¯„åˆ†
func calculatePerformanceScore(fpsRatio, memoryRatio, cpuRatio, fpsCV, memoryCV, cpuCV float64) float64 {
	// æƒé‡åˆ†é…ï¼šCPU 40%ï¼ŒFPS 30%ï¼Œå†…å­˜ 30%
	// å˜å¼‚ç³»æ•°æƒ©ç½šï¼šç¨³å®šæ€§è¶Šå·®ï¼Œæ‰£åˆ†è¶Šå¤š

	// FPSå¾—åˆ†ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
	fpsScore := 0.0
	if fpsRatio >= 1.0 {
		fpsScore = 100 // æŒå¹³æˆ–æ›´å¥½
	} else {
		fpsScore = fpsRatio * 100 // æŒ‰æ¯”ä¾‹å¾—åˆ†
	}

	// å†…å­˜å¾—åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
	memoryScore := 0.0
	if memoryRatio <= 1.0 {
		memoryScore = 100 // æŒå¹³æˆ–æ›´å¥½
	} else {
		memoryScore = (1.0 / memoryRatio) * 100 // å†…å­˜ä½¿ç”¨è¶Šå¤šï¼Œå¾—åˆ†è¶Šä½
	}

	// CPUå¾—åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
	cpuScore := 0.0
	if cpuRatio <= 1.0 {
		cpuScore = 100 // æŒå¹³æˆ–æ›´å¥½
	} else {
		cpuScore = (1.0 / cpuRatio) * 100 // CPUä½¿ç”¨è¶Šå¤šï¼Œå¾—åˆ†è¶Šä½
	}

	// ç¨³å®šæ€§æƒ©ç½šï¼ˆå˜å¼‚ç³»æ•°è¶Šé«˜ï¼Œæ‰£åˆ†è¶Šå¤šï¼‰
	stabilityPenalty := (fpsCV * 0.5) + (memoryCV * 0.3) + (cpuCV * 0.2)

	// ç»¼åˆå¾—åˆ†
	totalScore := (fpsScore * 0.3) + (memoryScore * 0.3) + (cpuScore * 0.4) - stabilityPenalty

	// ç¡®ä¿åœ¨0-100èŒƒå›´å†…
	if totalScore < 0 {
		totalScore = 0
	}
	if totalScore > 100 {
		totalScore = 100
	}

	return math.Round(totalScore*10) / 10
}

// analyzeSignificance åˆ†ææ€§èƒ½å·®å¼‚çš„æ˜¾è‘—æ€§
func analyzeSignificance(customSummary, nativeSummary map[string]interface{},
	fpsDiffPercent, memoryDiffPercent, cpuDiffPercent float64) map[string]interface{} {

	// æå–å˜å¼‚ç³»æ•°
	customFPSCV := customSummary["fps_cv"].(float64)
	customMemoryCV := customSummary["memory_cv"].(float64)
	customCPUCV := customSummary["cpu_cv"].(float64)

	// åˆ¤æ–­æ˜¾è‘—æ€§
	isFPSSignificant := math.Abs(fpsDiffPercent) > (customFPSCV * 2) // å·®å¼‚å¤§äº2å€å˜å¼‚ç³»æ•°
	isMemorySignificant := math.Abs(memoryDiffPercent) > (customMemoryCV * 2)
	isCPUSignificant := math.Abs(cpuDiffPercent) > (customCPUCV * 2)

	return map[string]interface{}{
		"fps_significant":    isFPSSignificant,
		"memory_significant": isMemorySignificant,
		"cpu_significant":    isCPUSignificant,

		"fps_confidence":    calculateConfidenceLevel(math.Abs(fpsDiffPercent), customFPSCV),
		"memory_confidence": calculateConfidenceLevel(math.Abs(memoryDiffPercent), customMemoryCV),
		"cpu_confidence":    calculateConfidenceLevel(math.Abs(cpuDiffPercent), customCPUCV),
	}
}

// calculateConfidenceLevel è®¡ç®—ç½®ä¿¡æ°´å¹³
func calculateConfidenceLevel(diffPercent, cv float64) string {
	if cv == 0 {
		return "high"
	}

	ratio := diffPercent / cv

	if ratio >= 3 {
		return "very high"
	} else if ratio >= 2 {
		return "high"
	} else if ratio >= 1 {
		return "medium"
	} else {
		return "low"
	}
}

// classifyPerformance åˆ†ç±»æ€§èƒ½è¡¨ç°
func classifyPerformance(fpsRatio, memoryRatio, cpuRatio,
	fpsDiffPercent, memoryDiffPercent, cpuDiffPercent float64) map[string]interface{} {

	// FPSåˆ†ç±»
	fpsCategory := ""
	if fpsDiffPercent >= 10 {
		fpsCategory = "excellent" // æ˜¾è‘—ä¼˜äº
	} else if fpsDiffPercent >= 0 {
		fpsCategory = "good" // ç•¥ä¼˜æˆ–æŒå¹³
	} else if fpsDiffPercent >= -10 {
		fpsCategory = "acceptable" // ç•¥å·®ä½†å¯æ¥å—
	} else if fpsDiffPercent >= -30 {
		fpsCategory = "poor" // è¾ƒå·®
	} else {
		fpsCategory = "bad" // å¾ˆå·®
	}

	// å†…å­˜åˆ†ç±»
	memoryCategory := ""
	if memoryDiffPercent <= -10 {
		memoryCategory = "excellent" // æ˜¾è‘—èŠ‚çœå†…å­˜
	} else if memoryDiffPercent <= 0 {
		memoryCategory = "good" // ç•¥çœæˆ–æŒå¹³
	} else if memoryDiffPercent <= 20 {
		memoryCategory = "acceptable" // ç•¥å¤šä½†å¯æ¥å—
	} else if memoryDiffPercent <= 50 {
		memoryCategory = "poor" // è¾ƒå¤š
	} else {
		memoryCategory = "bad" // å¾ˆå¤š
	}

	// CPUåˆ†ç±»
	cpuCategory := ""
	if cpuDiffPercent <= -10 {
		cpuCategory = "excellent" // æ˜¾è‘—èŠ‚çœCPU
	} else if cpuDiffPercent <= 0 {
		cpuCategory = "good" // ç•¥çœæˆ–æŒå¹³
	} else if cpuDiffPercent <= 20 {
		cpuCategory = "acceptable" // ç•¥å¤šä½†å¯æ¥å—
	} else if cpuDiffPercent <= 50 {
		cpuCategory = "poor" // è¾ƒå¤š
	} else {
		cpuCategory = "bad" // å¾ˆå¤š
	}

	return map[string]interface{}{
		"fps":    fpsCategory,
		"memory": memoryCategory,
		"cpu":    cpuCategory,
	}
}

// generateConclusion ç”Ÿæˆæµ‹è¯•ç»“è®º
func generateConclusion(comparison map[string]interface{}) string {
	if comparison == nil {
		return "æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆç»“è®º"
	}

	performanceScore := comparison["performance_score"].(float64)
	fpsDiffPercent := comparison["fps_diff_percent"].(float64)
	memoryDiffPercent := comparison["memory_diff_percent"].(float64)
	cpuDiffPercent := comparison["cpu_diff_percent"].(float64)

	performanceCategory := comparison["performance_category"].(map[string]interface{})
	fpsCategory := performanceCategory["fps"].(string)
	memoryCategory := performanceCategory["memory"].(string)
	cpuCategory := performanceCategory["cpu"].(string)

	// æ ¹æ®ç»¼åˆè¯„åˆ†å’Œå„é¡¹æŒ‡æ ‡ç”Ÿæˆç»“è®º
	if performanceScore >= 90 {
		return fmt.Sprintf("âœ… æ€§èƒ½ä¼˜ç§€ (%.1fåˆ†)ã€‚è‡ªå®šä¹‰æ§ä»¶åœ¨ä¿æŒè§†è§‰æ•ˆæœçš„åŒæ—¶ï¼Œæ€§èƒ½è¡¨ç°ä¼˜äºæˆ–æ¥è¿‘åŸç”Ÿæ§ä»¶ã€‚", performanceScore)
	} else if performanceScore >= 80 {
		return fmt.Sprintf("ğŸŸ¡ æ€§èƒ½è‰¯å¥½ (%.1fåˆ†)ã€‚è‡ªå®šä¹‰æ§ä»¶æ€§èƒ½å¯æ¥å—ï¼ŒFPS: %s, å†…å­˜: %s, CPU: %sã€‚",
			performanceScore, fpsCategory, memoryCategory, cpuCategory)
	} else if performanceScore >= 70 {
		return fmt.Sprintf("ğŸŸ¡ æ€§èƒ½ä¸€èˆ¬ (%.1fåˆ†)ã€‚å­˜åœ¨ä¸€å®šçš„æ€§èƒ½å¼€é”€ï¼Œå»ºè®®ä¼˜åŒ–ã€‚FPSå·®å¼‚: %.1f%%, å†…å­˜å¼€é”€: %.1f%%, CPUå¼€é”€: %.1f%%ã€‚",
			performanceScore, fpsDiffPercent, memoryDiffPercent, cpuDiffPercent)
	} else {
		return fmt.Sprintf("ğŸ”´ æ€§èƒ½è¾ƒå·® (%.1fåˆ†)ã€‚æ€§èƒ½å¼€é”€è¾ƒå¤§ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–ã€‚FPSæ˜¾è‘—é™ä½ï¼Œå†…å­˜å’ŒCPUä½¿ç”¨æ˜æ˜¾å¢åŠ ã€‚",
			performanceScore)
	}
}

// EnsureOutputDir ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
func EnsureOutputDir(dirPath string) error {
	return os.MkdirAll(dirPath, 0755)
}

// GetTimestamp è·å–æ—¶é—´æˆ³å­—ç¬¦ä¸²
func GetTimestamp() string {
	return time.Now().Format("2006-01-02_15-04-05")
}

// PrintComparison æ‰“å°å¯¹æ¯”ç»“æœ
func PrintComparison(comparison *ComponentComparison) {
	if comparison == nil {
		fmt.Println("å¯¹æ¯”ç»“æœä¸ºç©º")
		return
	}

	fmt.Println("\nğŸ“Š ========== æ€§èƒ½å¯¹æ¯”ç»“æœ ==========")

	// æ‰“å°è‡ªå®šä¹‰æ§ä»¶æ€§èƒ½
	customSummary := comparison.CustomSummary
	fmt.Printf("\nğŸ”§ è‡ªå®šä¹‰æ§ä»¶æ€§èƒ½:\n")
	fmt.Printf("  æ ·æœ¬æ•°: %d\n", customSummary["sample_count"])
	fmt.Printf("  FPS: %.1f (%.1f-%.1f) Ïƒ=%.2f CV=%.1f%%\n",
		customSummary["fps_avg"], customSummary["fps_min"],
		customSummary["fps_max"], customSummary["fps_std"], customSummary["fps_cv"])
	fmt.Printf("  å†…å­˜: %.2fMB (%.2f-%.2f) Ïƒ=%.2f CV=%.1f%%\n",
		customSummary["memory_avg"], customSummary["memory_min"],
		customSummary["memory_max"], customSummary["memory_std"], customSummary["memory_cv"])
	fmt.Printf("  CPU: %.1f%% (%.1f-%.1f) Ïƒ=%.2f CV=%.1f%%\n",
		customSummary["cpu_avg"], customSummary["cpu_min"],
		customSummary["cpu_max"], customSummary["cpu_std"], customSummary["cpu_cv"])

	// æ‰“å°åŸç”Ÿæ§ä»¶æ€§èƒ½
	nativeSummary := comparison.NativeSummary
	fmt.Printf("\nğŸ”§ åŸç”Ÿæ§ä»¶æ€§èƒ½:\n")
	fmt.Printf("  æ ·æœ¬æ•°: %d\n", nativeSummary["sample_count"])
	fmt.Printf("  FPS: %.1f (%.1f-%.1f) Ïƒ=%.2f CV=%.1f%%\n",
		nativeSummary["fps_avg"], nativeSummary["fps_min"],
		nativeSummary["fps_max"], nativeSummary["fps_std"], nativeSummary["fps_cv"])
	fmt.Printf("  å†…å­˜: %.2fMB (%.2f-%.2f) Ïƒ=%.2f CV=%.1f%%\n",
		nativeSummary["memory_avg"], nativeSummary["memory_min"],
		nativeSummary["memory_max"], nativeSummary["memory_std"], nativeSummary["memory_cv"])
	fmt.Printf("  CPU: %.1f%% (%.1f-%.1f) Ïƒ=%.2f CV=%.1f%%\n",
		nativeSummary["cpu_avg"], nativeSummary["cpu_min"],
		nativeSummary["cpu_max"], nativeSummary["cpu_std"], nativeSummary["cpu_cv"])

	// æ‰“å°å¯¹æ¯”ç»“æœ
	comp := comparison.Comparison
	fmt.Printf("\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”åˆ†æ:\n")
	fmt.Printf("  FPSæ¯”ç‡: %.3f (å·®å¼‚: %.1f%%)\n",
		comp["fps_ratio"], comp["fps_diff_percent"])
	fmt.Printf("  å†…å­˜æ¯”ç‡: %.3f (å·®å¼‚: %.1f%%)\n",
		comp["memory_ratio"], comp["memory_diff_percent"])
	fmt.Printf("  CPUæ¯”ç‡: %.3f (å·®å¼‚: %.1f%%)\n",
		comp["cpu_ratio"], comp["cpu_diff_percent"])

	fmt.Printf("\nğŸ† ç»¼åˆæ€§èƒ½è¯„åˆ†: %.1f/100\n", comp["performance_score"])

	// æ‰“å°æ˜¾è‘—æ€§åˆ†æ
	sig := comp["significance"].(map[string]interface{})
	fmt.Printf("\nğŸ” æ˜¾è‘—æ€§åˆ†æ:\n")
	fmt.Printf("  FPSæ˜¾è‘—æ€§: %v (ç½®ä¿¡åº¦: %s)\n",
		sig["fps_significant"], sig["fps_confidence"])
	fmt.Printf("  å†…å­˜æ˜¾è‘—æ€§: %v (ç½®ä¿¡åº¦: %s)\n",
		sig["memory_significant"], sig["memory_confidence"])
	fmt.Printf("  CPUæ˜¾è‘—æ€§: %v (ç½®ä¿¡åº¦: %s)\n",
		sig["cpu_significant"], sig["cpu_confidence"])

	fmt.Printf("\nğŸ’¡ ç»“è®º: %s\n", comparison.Conclusion)
	fmt.Println("====================================\n")
}
